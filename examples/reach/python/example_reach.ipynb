{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f744f796",
   "metadata": {},
   "source": [
    "# Querying Hierarchical Data Using the `reach` Action in the `NETWORK` Actionset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408abc0",
   "metadata": {},
   "source": [
    "In this demonstration, we load a sample company's organization structure into our CAS server, and query it to identify all employees in a single manager's reporting structure.\n",
    "\n",
    "This example emulates the same query, but conducted using recursive SQL queries, as shown in [Recursive Query with PROC SQL](https://kansascode.blogspot.com/2021/06/recursive-query-with-proc-sql.html?m=1) as well as [Learn PostgreSQL Recursive Query By Example](https://www.postgresqltutorial.com/postgresql-recursive-query/).\n",
    "\n",
    "We show how through use of the `reach` action, we identify all employees who report to a manager named __Megan Berry__. Traversal algorithms allow us to avoid recursion, making our code simpler to understand and debug.\n",
    "\n",
    "----------------\n",
    "\n",
    "The basic flow of this notebook is as follows:\n",
    "1. Load the organizational structure into a Pandas DataFrame as a set of links.\n",
    "2. Connect to a CAS server and upload our DataFrame.\n",
    "3. Execute the `reach` action and fetch the results.\n",
    "4. Compare results with the known results from the examples referenced above.\n",
    "\n",
    "----------------\n",
    "__Prepared by:__\n",
    "Damian Herrick (<i class=\"fa fa-github\" aria-hidden=\"true\"></i>: [dtherrick](www.github.com/dtherrick))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98d755",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The modules below are needed for this exercise.\n",
    "\n",
    "| Module             | Description                                                                        |\n",
    "|:-------------------|:----------------------------------------------------------------------------------:|\n",
    "| `os`               | Allows access to environment variables.                                            |\n",
    "| `swat`             | SAS Python module that orchestrates communication with a CAS server.               |\n",
    "| `pandas`           | Data management module we use for preparation of local data.                       |\n",
    "| `graphviz.Digraph` | Used to display the organizational structure with the results of our reach query.  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33b9f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T15:52:07.885893Z",
     "start_time": "2021-11-08T15:52:07.462142Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import swat\n",
    "import pandas as pd\n",
    "\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d6820",
   "metadata": {},
   "source": [
    "## Sample Data\n",
    "\n",
    "We take our sample data from the original post about recursive SQL.\n",
    "\n",
    "| `employee_id` |     `full_name`     | `manager_id` |\n",
    "|:-------------:|:-------------------:|:------------:|\n",
    "|       1       | 'Michael North'     |     NULL     |\n",
    "|       2       | 'Megan Berry'       |       1      |\n",
    "|       3       | 'Sarah Berry'       |       1      |\n",
    "|       4       | 'Zoe Black'         |       1      |\n",
    "|       5       | 'Tim James'         |       1      |\n",
    "|       6       | 'Bella Tucker'      |       2      |\n",
    "|       7       | 'Ryan Metcalfe'     |       2      |\n",
    "|       8       | 'Max Mills'         |       2      |\n",
    "|       9       | 'Benjamin Glover'   |       2      |\n",
    "|      10       | 'Carolyn Henderson' |       3      |\n",
    "|      11       | 'Nicola Kelly'      |       3      |\n",
    "|      12       | 'Alexandra Climo'   |       3      |\n",
    "|      13       | 'Dominic King'      |       3      |\n",
    "|      14       | 'Leonard Gray'      |       4      |\n",
    "|      15       | 'Eric Rampling'     |       4      |\n",
    "|      16       | 'Piers Paige'       |       7      |\n",
    "|      17       | 'Ryan Henderson'    |       7      |\n",
    "|      18       | 'Frank Tucker'      |       8      |\n",
    "|      19       | 'Nathan Ferguson'   |       8      |\n",
    "|      20       | 'Kevin Rampling'    |       8      |\n",
    "\n",
    "For our purposes, let's put that data into a master dataframe, which we can use both in our reach calculations as well as for verifications and visualization later in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec41b2b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T15:52:10.339356Z",
     "start_time": "2021-11-08T15:52:10.087680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4aa90_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >employee_id</th>\n",
       "      <th class=\"col_heading level0 col1\" >full_name</th>\n",
       "      <th class=\"col_heading level0 col2\" >manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_4aa90_row0_col1\" class=\"data row0 col1\" >Michael North</td>\n",
       "      <td id=\"T_4aa90_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_4aa90_row1_col1\" class=\"data row1 col1\" >Megan Berry</td>\n",
       "      <td id=\"T_4aa90_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_4aa90_row2_col1\" class=\"data row2 col1\" >Sarah Berry</td>\n",
       "      <td id=\"T_4aa90_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_4aa90_row3_col1\" class=\"data row3 col1\" >Zoe Black</td>\n",
       "      <td id=\"T_4aa90_row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_4aa90_row4_col1\" class=\"data row4 col1\" >Tim James</td>\n",
       "      <td id=\"T_4aa90_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_4aa90_row5_col1\" class=\"data row5 col1\" >Bella Tucker</td>\n",
       "      <td id=\"T_4aa90_row5_col2\" class=\"data row5 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_4aa90_row6_col1\" class=\"data row6 col1\" >Ryan Metcalfe</td>\n",
       "      <td id=\"T_4aa90_row6_col2\" class=\"data row6 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_4aa90_row7_col1\" class=\"data row7 col1\" >Max Mills</td>\n",
       "      <td id=\"T_4aa90_row7_col2\" class=\"data row7 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_4aa90_row8_col1\" class=\"data row8 col1\" >Benjamin Glover</td>\n",
       "      <td id=\"T_4aa90_row8_col2\" class=\"data row8 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_4aa90_row9_col1\" class=\"data row9 col1\" >Carolyn Henderson</td>\n",
       "      <td id=\"T_4aa90_row9_col2\" class=\"data row9 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row10_col0\" class=\"data row10 col0\" >11</td>\n",
       "      <td id=\"T_4aa90_row10_col1\" class=\"data row10 col1\" >Nicola Kelly</td>\n",
       "      <td id=\"T_4aa90_row10_col2\" class=\"data row10 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row11_col0\" class=\"data row11 col0\" >12</td>\n",
       "      <td id=\"T_4aa90_row11_col1\" class=\"data row11 col1\" >Alexandra Climo</td>\n",
       "      <td id=\"T_4aa90_row11_col2\" class=\"data row11 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row12_col0\" class=\"data row12 col0\" >13</td>\n",
       "      <td id=\"T_4aa90_row12_col1\" class=\"data row12 col1\" >Dominic King</td>\n",
       "      <td id=\"T_4aa90_row12_col2\" class=\"data row12 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row13_col0\" class=\"data row13 col0\" >14</td>\n",
       "      <td id=\"T_4aa90_row13_col1\" class=\"data row13 col1\" >Leonard Gray</td>\n",
       "      <td id=\"T_4aa90_row13_col2\" class=\"data row13 col2\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row14_col0\" class=\"data row14 col0\" >15</td>\n",
       "      <td id=\"T_4aa90_row14_col1\" class=\"data row14 col1\" >Eric Rampling</td>\n",
       "      <td id=\"T_4aa90_row14_col2\" class=\"data row14 col2\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row15_col0\" class=\"data row15 col0\" >16</td>\n",
       "      <td id=\"T_4aa90_row15_col1\" class=\"data row15 col1\" >Piers Paige</td>\n",
       "      <td id=\"T_4aa90_row15_col2\" class=\"data row15 col2\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row16_col0\" class=\"data row16 col0\" >17</td>\n",
       "      <td id=\"T_4aa90_row16_col1\" class=\"data row16 col1\" >Ryan Henderson</td>\n",
       "      <td id=\"T_4aa90_row16_col2\" class=\"data row16 col2\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row17_col0\" class=\"data row17 col0\" >18</td>\n",
       "      <td id=\"T_4aa90_row17_col1\" class=\"data row17 col1\" >Frank Tucker</td>\n",
       "      <td id=\"T_4aa90_row17_col2\" class=\"data row17 col2\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row18_col0\" class=\"data row18 col0\" >19</td>\n",
       "      <td id=\"T_4aa90_row18_col1\" class=\"data row18 col1\" >Nathan Ferguson</td>\n",
       "      <td id=\"T_4aa90_row18_col2\" class=\"data row18 col2\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4aa90_row19_col0\" class=\"data row19 col0\" >20</td>\n",
       "      <td id=\"T_4aa90_row19_col1\" class=\"data row19 col1\" >Kevin Rampling</td>\n",
       "      <td id=\"T_4aa90_row19_col2\" class=\"data row19 col2\" >8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x117a32430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a list of tuples, along with a list of column names, to create the master dataframe.\n",
    "colNames = [\"employee_id\", \"full_name\", \"manager_id\"]\n",
    "data = [\n",
    "    (1, \"Michael North\", 0),\n",
    "    (2, \"Megan Berry\", 1),\n",
    "    (3, \"Sarah Berry\", 1),\n",
    "    (4, \"Zoe Black\", 1),\n",
    "    (5, \"Tim James\", 1),\n",
    "    (6, \"Bella Tucker\", 2),\n",
    "    (7, \"Ryan Metcalfe\", 2),\n",
    "    (8, \"Max Mills\", 2),\n",
    "    (9, \"Benjamin Glover\", 2),\n",
    "    (10, \"Carolyn Henderson\", 3),\n",
    "    (11, \"Nicola Kelly\", 3),\n",
    "    (12, \"Alexandra Climo\", 3),\n",
    "    (13, \"Dominic King\", 3),\n",
    "    (14, \"Leonard Gray\", 4),\n",
    "    (15, \"Eric Rampling\", 4),\n",
    "    (16, \"Piers Paige\", 7),\n",
    "    (17, \"Ryan Henderson\", 7),\n",
    "    (18, \"Frank Tucker\", 8),\n",
    "    (19, \"Nathan Ferguson\", 8),\n",
    "    (20, \"Kevin Rampling\", 8), \n",
    "]\n",
    "# create the dataframe from the above source data.\n",
    "dfMasterData = pd.DataFrame(data, columns=colNames)\n",
    "\n",
    "# display the table, but we don't care about the index for this exercise.\n",
    "dfMasterData.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007d409",
   "metadata": {},
   "source": [
    "## Connect to our Viya (CAS) server\n",
    "\n",
    "We now need to connect to our CAS server. Contact your SAS administrator for the proper credentials to connect to CAS using `python-swat`.\n",
    "\n",
    "As a convention, I keep my CAS host and port set as environment variables. This allows me to both avoid placing user-specific data in notebooks, as well as adds a layer of security.\n",
    "\n",
    "For ease-of-reading, I assign those environment variables into `host` and `port` variables, then pass them into the connection statement.\n",
    "\n",
    "Once connected, we need access to the `PROC NETWORK` actions. In CAS terminology, that is an `actionset` so we load that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0304579e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T15:52:13.727851Z",
     "start_time": "2021-11-08T15:52:12.131859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orgrd061.unx.sas.com\n",
      "23404\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "host = os.environ['CAS_HOST_ORGRD']\n",
    "port = int(os.environ['CAS_PORT'])\n",
    "\n",
    "# Connect to the server\n",
    "conn = swat.CAS(host, port)\n",
    "\n",
    "# Load the actionsets we need\n",
    "conn.loadactionset('network')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01885665",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load source tables into CAS\n",
    "\n",
    "All of the `network` actions require a graph table. In this exercise, we simply need to pass the action a `LinkSetIn` table that represents the relationships between the employees, and a `NodeSubsetIn` table that represents the specific nodes whose reach we wish to calculate. \n",
    "\n",
    "As we defined in the master data above, we only need to pass the `employee_id` and `manager_id` values from each row to create the links table. Since __Michael North__ does not have a manager, we want to skip his record in the links table we upload to CAS. The easiest way is to create an intermediate dataframe using the pandas `loc` method to exclude the first row, and limit to only the `employee_id` and `manager_id` columns.\n",
    "\n",
    "For the `NodeSubsetIn` table, we create an intermediate dataframe with a specific format. Its source must be a list of dicts, where each dictionary has two keys: `node` and `reach`. `node`'s value is the identifier of the node whose reach we calculate. `reach` is the order of reach calculations we want to calculate. Since we are only calculating for one source node, `reach`'s value is 1.\n",
    "\n",
    "Once the intermediate dataframes are created, we upload them to CAS using the `upload` method. The `casout=` argument allows us to define the names of the CAS tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688f55b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T20:24:22.696559Z",
     "start_time": "2021-11-05T20:24:22.537712Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfLinkSetIn = dfMasterData.loc[dfMasterData.employee_id>1, ['employee_id', 'manager_id']]\n",
    "dfNodeSubsetIn = pd.DataFrame([{'node': 2, 'reach': 1}])\n",
    "\n",
    "swat.options.cas.print_messages=False\n",
    "\n",
    "_ = conn.upload(dfLinkSetIn, casout=dict(name='LinkSetIn', replace=True))\n",
    "_ = conn.upload(dfNodeSubsetIn, casout=dict(name='NodeSubsetIn', replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789794ee",
   "metadata": {},
   "source": [
    "## Find all employees who report to Megan Berry\n",
    "\n",
    "We can find all of Megan's subordinates using the `reach` action.\n",
    "\n",
    "The reach action takes several options:\n",
    "* `links`: The name of the source table that contains the full set of links that describe our graph.\n",
    "* `nodessubset`: The name of the source table that contains the nodes and reach we wish to search against.\n",
    "* `direction`: Define whether the graph in the `links` option is a directed or undirected graph. For this exercise, we must explicitly state that this is a directed graph using the string `directed`.\n",
    "* `linksvar`: We include this option because we did not name our columns `from` and `to`. (If we had, we could ignore this option). For our calculation, we pass a dictionary where `manager_id` is the `from` value, and `employee_id` is the `to` value.\n",
    "* `maxreach`: an integer value that defines how many levels deep we should calculate the reach. We use 2 in this case.\n",
    "* `outReachNodes`: an output table with the nodes that are included in the reach calculations.\n",
    "* `outReachLinks`: an output table with the link pairs that are included in the reach calculations.\n",
    "* `outCounts`: an output summary table that has the total count of nodes included in the reach calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744afe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T15:51:33.861936Z",
     "start_time": "2021-10-22T15:51:33.644658Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "conn.network.reach(\n",
    "    direction     = \"directed\",\n",
    "    links         = {\"name\":\"LinkSetIn\"},\n",
    "    linksvar      = {\"from\": \"manager_id\", \"to\": \"employee_id\"},\n",
    "    nodessubset   = {\"name\":\"NodeSubSetIn\"},\n",
    "    outReachNodes = {\"name\":\"ReachNodes\",  \"replace\":True},\n",
    "    outReachLinks = {\"name\":\"ReachLinks\",  \"replace\":True},\n",
    "    outCounts     = {\"name\":\"ReachCounts\", \"replace\":True},\n",
    "    maxreach      = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeebae6",
   "metadata": {},
   "source": [
    "## Review the output tables\n",
    "\n",
    "If the reach action was successful, it will output some summary and log information in the notebook. We asked it to generate three tables, so let's just fetch those tables and verify that the data looks OK.\n",
    "\n",
    "For the `ReachLinks` table, a quick pass at the first four rows shows Megan has four direct reports. If we glance back at the master data above, we see that, yes, her employee id is 2, and the `ReachLinks` table shows four employees with a manager id of 2.\n",
    "\n",
    "For `ReachCounts`, we see that node 2 connects to 10 nodes. This is good, since there are 20 total nodes - we know Megan doesn't manage everyone.\n",
    "\n",
    "For `ReachNodes`, we simply verify that there are 10 rows (nodes) included.\n",
    "\n",
    "Based on the quick verification, all three tables look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f805f63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T15:51:51.982886Z",
     "start_time": "2021-10-22T15:51:48.594728Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.fetch('ReachLinks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8312e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T15:51:52.070099Z",
     "start_time": "2021-10-22T15:51:51.985210Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.fetch('ReachNodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd557150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T15:51:52.131243Z",
     "start_time": "2021-10-22T15:51:52.071941Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.fetch('ReachCounts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8b896",
   "metadata": {},
   "source": [
    "## Verify that our call to the reach action matches the output of recursive SQL\n",
    "\n",
    "From the initial PostgreSQL recursive SQL article, we expect these results:\n",
    "\n",
    " employee_id  | manager_id   |    full_name\n",
    "-------------:|:------------:|:-----------------\n",
    "           2  |          1   | Megan Berry\n",
    "           6  |          2   | Bella Tucker\n",
    "           7  |          2   | Ryan Metcalfe\n",
    "           8  |          2   | Max Mills\n",
    "           9  |          2   | Benjamin Glover\n",
    "          16  |          7   | Piers Paige\n",
    "          17  |          7   | Ryan Henderson\n",
    "          18  |          8   | Frank Tucker\n",
    "          19  |          8   | Nathan Ferguson\n",
    "          20  |          8   | Kevin Rampling\n",
    "          \n",
    "Let's use the `ReachNodes` table and the `dfMasterData` dataframe to try to reproduce this table.\n",
    "\n",
    "Our approach:\n",
    "1. Create a list of only the node id's in the `ReachNodes` returned by the reach action. A simple list comprehension accomplishes this, in the `report_list` variable.\n",
    "2. Then, use that list with the master data to generate a boolean pandas series, where values are True if they are in Megan's reporting reach, False if not.\n",
    "3. Filter the master dataframe to create a `Reports` table we can use to compare.\n",
    "4. Display that final reports table.\n",
    "\n",
    "We see that, yes, the reach action provides the same results as the recursive SQL statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1eb8b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T15:51:52.194425Z",
     "start_time": "2021-10-22T15:51:52.133826Z"
    }
   },
   "outputs": [],
   "source": [
    "report_list = [int(i) for i in  conn.fetch('ReachNodes')['Fetch']['node'].to_list()]\n",
    "\n",
    "reports_series = dfMasterData.employee_id.isin(report_list)\n",
    "dfReports = dfMasterData[reports_series]\n",
    "\n",
    "dfReports.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa61c7",
   "metadata": {},
   "source": [
    "## Bonus: Verify Results Visually\n",
    "\n",
    "Finally, let's produce a tree diagram of our organizational structure, and highlight the employees in Megan's reporting structure. This approach allows us to quickly verify whether the reach action produced the correct reporting structure.\n",
    "\n",
    "We use `graphviz` since it provides an easy means to programmatically create a directed network graph diagram. Since we can't directly translate pandas dataframes to graphviz dot syntax, we need to convert our dataframes to Python lists.\n",
    "\n",
    "Our approach is as follows:\n",
    "1. Create a `graph` object from the master dataframe. Calling the `to_dict` method with `orient='records'` set returns a list of dictionaries, one for each row in the dataframe.\n",
    "2. Create two lists of tuples - one for the reporting list, and one for everyone else. We simply use list comprehensions filtered by the `report_list` we created above to generate these variables.\n",
    "3. Define our graphviz object as a `Digraph`.\n",
    "4. Add the nodes in the reporting structure. For our purposes, we highlight by filling these nodes with light blue.\n",
    "5. Add all remaining nodes. Leave them unfilled.\n",
    "6. Use the full graph - which already has the link relationships - to add the links to our visualization.\n",
    "7. Since this is a wide image, we create a `final_plot` object in which we pass our dot language and use the `unflatten` option with a `stagger` value of 4.\n",
    "8. Finally, display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff66406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T15:51:53.359580Z",
     "start_time": "2021-10-22T15:51:52.927384Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = dfMasterData.to_dict(orient='records')\n",
    "\n",
    "report_nodes = [(node['employee_id'], node['full_name']) for node in graph if node['employee_id'] in report_list]\n",
    "other_nodes = [(node['employee_id'], node['full_name']) for node in graph if node['employee_id'] not in report_list]\n",
    "\n",
    "dot = Digraph()\n",
    "\n",
    "for item in report_nodes:\n",
    "    dot.node(str(item[0]), item[1], style='filled', fillcolor='lightblue')\n",
    "\n",
    "for item in other_nodes:\n",
    "    dot.node(str(item[0]), item[1])\n",
    "\n",
    "# note that we skip the first row in \"graph\" because that is the head of the tree with no manager. We don't need a phantom link called \"0\"\n",
    "for pair in graph[1:]:\n",
    "    dot.edge(str(pair['manager_id']), str(pair['employee_id']))\n",
    "\n",
    "final_plot = dot.unflatten(stagger=4)\n",
    "\n",
    "final_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f741e8",
   "metadata": {},
   "source": [
    "## Clean up everything. \n",
    "\n",
    "Make sure we know what tables we created, drop them, and close our connection.\n",
    "(This is probably overkill, since everything in this session is ephemeral anyway, but good practice nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285972fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = conn.tableinfo()[\"TableInfo\"][\"Name\"].to_list()\n",
    "\n",
    "for table in table_list:\n",
    "    conn.droptable(name=table, quiet=True)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f09861",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we used the `reach` action in the `network` actionset for SAS Viya to determine all employees in a single person's reporting structure. We checked our results against the same calculations performed by recursive SQL statements in both PostgreSQL and SAS `PROC SQL`. \n",
    "\n",
    "Both a results table and a network diagram demonstrate that the reach action results are equivalent to the recursive SQL statements. Using the reach action is both less verbose, and requires less debugging and design than developing custom recursive queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
